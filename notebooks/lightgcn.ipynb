{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:38.728354986Z",
     "start_time": "2023-12-12T17:45:38.582198760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import random \n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:39.109711308Z",
     "start_time": "2023-12-12T17:45:38.914588890Z"
    }
   },
   "id": "7a1792ec008cba57"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import optuna\n",
    "import wandb "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:41.274652451Z",
     "start_time": "2023-12-12T17:45:39.154735979Z"
    }
   },
   "id": "8fdadeaaae423a1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing \n",
    "from torch_geometric.utils import degree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:50.599012844Z",
     "start_time": "2023-12-12T17:45:41.211790378Z"
    }
   },
   "id": "9e60dae25bb1290b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:53.517923022Z",
     "start_time": "2023-12-12T17:45:50.382162468Z"
    }
   },
   "id": "4be7a1bc87aa7157"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:54.432346906Z",
     "start_time": "2023-12-12T17:45:53.500452802Z"
    }
   },
   "id": "4ce3e598624f9831"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:54.461384117Z",
     "start_time": "2023-12-12T17:45:54.394482358Z"
    }
   },
   "id": "f1fb2146816ffb45"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpkyoyetera\u001B[0m (\u001B[33mhidden-leaf\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.406977621Z",
     "start_time": "2023-12-12T17:45:54.426785723Z"
    }
   },
   "id": "6285dc9b5749954b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  item_id  rating  timestamp\n0      196      242       3  881250949\n1      186      302       3  891717742\n2       22      377       1  878887116\n3      244       51       2  880606923\n4      166      346       1  886397596",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n      <td>878887116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n      <td>880606923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n      <td>886397596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "df = pd.read_csv('../data/ml-100k/u.data', sep='\\t', names=column_names)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.528906248Z",
     "start_time": "2023-12-12T17:45:57.405031392Z"
    }
   },
   "id": "c2e9cd466b25bb5b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 80000\n",
      "Test size: 20000\n"
     ]
    }
   ],
   "source": [
    "# 80/20 split\n",
    "train_data, test_data = train_test_split(df.values, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns=column_names)\n",
    "test_df = pd.DataFrame(test_data, columns=column_names)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.558250602Z",
     "start_time": "2023-12-12T17:45:57.505194816Z"
    }
   },
   "id": "cb0443cca8d1e55b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 943\n",
      "Number of unique items: 1653\n"
     ]
    }
   ],
   "source": [
    "# Relabel user and item IDs to start from 0\n",
    "user_le, item_le = pp.LabelEncoder(), pp.LabelEncoder()\n",
    "\n",
    "train_df['user_id_index'] = user_le.fit_transform(train_df['user_id'].values)\n",
    "train_df['item_id_index'] = item_le.fit_transform(train_df['item_id'].values)\n",
    "\n",
    "train_user_ids = train_df['user_id'].unique()\n",
    "train_item_ids = train_df['item_id'].unique()\n",
    "\n",
    "print(f\"Number of unique users: {len(train_user_ids)}\")\n",
    "print(f\"Number of unique items: {len(train_item_ids)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.697693170Z",
     "start_time": "2023-12-12T17:45:57.527819657Z"
    }
   },
   "id": "524e15394317878a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 19969\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df[(test_df['user_id'].isin(train_user_ids)) & (test_df['item_id'].isin(train_item_ids))]\n",
    "print(f\"Test size: {len(test_df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.833202967Z",
     "start_time": "2023-12-12T17:45:57.587444052Z"
    }
   },
   "id": "28b5aa7f4fdbf96c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_df['user_id_index'] = user_le.transform(test_df['user_id'].values)\n",
    "test_df['item_id_index'] = item_le.transform(test_df['item_id'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.857108973Z",
     "start_time": "2023-12-12T17:45:57.633103761Z"
    }
   },
   "id": "25c4ca25d9bd6e66"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 943\n",
      "Number of unique items: 1653\n"
     ]
    }
   ],
   "source": [
    "n_users = train_df['user_id_index'].nunique()\n",
    "n_items = train_df['item_id_index'].nunique()\n",
    "\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of unique items: {n_items}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:45:57.872250974Z",
     "start_time": "2023-12-12T17:45:57.633893647Z"
    }
   },
   "id": "2e41d9f131076d5f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T18:57:14.780897916Z",
     "start_time": "2023-12-11T18:57:14.751906524Z"
    }
   },
   "id": "4223ee4168abb26a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1455052a01e5be76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mini-batch sampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5628c5d328d36025"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:54:17.680791548Z",
     "start_time": "2023-12-11T22:54:17.556309484Z"
    }
   },
   "id": "23274bb8058997e5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 85, 161, 217, 326, 637, 671, 805, 929], device='cuda:0'),\n tensor([1270, 1196, 1145, 1230, 1578, 1217, 1038, 1223], device='cuda:0'),\n tensor([1792, 1442, 1058, 1878, 1019,  976, 2557, 2149], device='cuda:0'))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_loader(data, _batch_size, n_usr, n_itm):\n",
    "    \n",
    "    def negative_sampler(x):\n",
    "        while True:\n",
    "            neg_id = random.randint(0, n_itm-1)\n",
    "            if neg_id not in x:\n",
    "                return neg_id\n",
    "    \n",
    "    intersection_df = data.groupby(\"user_id_index\")[\"item_id_index\"].apply(list).reset_index()\n",
    "    indices = [x for x in range(n_usr)]\n",
    "    \n",
    "    if n_usr < _batch_size:\n",
    "        _users = [random.choice(indices) for _ in range(_batch_size)]\n",
    "    else:\n",
    "        _users = random.sample(indices, _batch_size)\n",
    "    \n",
    "    _users.sort()\n",
    "    users_df = pd.DataFrame(_users, columns=[\"users\"])\n",
    "    \n",
    "    intersection_df = pd.merge(intersection_df, users_df, how=\"right\", left_on=\"user_id_index\", right_on=\"users\")\n",
    "    positive_items = intersection_df[\"item_id_index\"].apply(lambda x : random.choice(x)).values\n",
    "    negative_items = intersection_df[\"item_id_index\"].apply(lambda x : negative_sampler(x)).values\n",
    "    \n",
    "    return torch.LongTensor(list(_users)).to(device), \\\n",
    "        torch.LongTensor(list(positive_items)).to(device) + n_usr, \\\n",
    "        torch.LongTensor(list(negative_items)).to(device) + n_usr\n",
    "\n",
    "# test\n",
    "data_loader(train_df, 8, n_users, n_items)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:27.582402131Z",
     "start_time": "2023-12-12T17:46:23.882126472Z"
    }
   },
   "id": "ceea04615cc11fb5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:30.993132463Z",
     "start_time": "2023-12-12T17:46:30.859144474Z"
    }
   },
   "id": "c00a964a3274cc41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edge Index "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d064b2f935e19f9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "u_t = torch.LongTensor(train_df.user_id_index)\n",
    "i_t = torch.LongTensor(train_df.item_id_index) + n_users\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:31.516555602Z",
     "start_time": "2023-12-12T17:46:31.362911320Z"
    }
   },
   "id": "77acaff5bd98a371"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 806,  473,  462,  ..., 1417, 1264, 1142],\n        [2347, 1601, 1210,  ...,  436,  283,  221]], device='cuda:0')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index = torch.stack((\n",
    "    torch.cat([u_t, i_t]), \n",
    "    torch.cat([i_t, u_t]))\n",
    ").to(device)  # .to(torch.int64)\n",
    "\n",
    "train_edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:35.002719228Z",
     "start_time": "2023-12-12T17:46:34.831634547Z"
    }
   },
   "id": "dcf342484dd607c8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:36.063663062Z",
     "start_time": "2023-12-12T17:46:35.916511832Z"
    }
   },
   "id": "de6231c14cbf17ad"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1142,  221], device='cuda:0'), tensor([ 806, 2347], device='cuda:0'))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm shapes \n",
    "train_edge_index[:, -1], train_edge_index[:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:37.789625529Z",
     "start_time": "2023-12-12T17:46:37.601445966Z"
    }
   },
   "id": "6571fd40b6f61448"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 221, 1142], device='cuda:0'), tensor([2347,  806], device='cuda:0'))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index[:, len(train_df)-1], train_edge_index[:, len(train_df)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:38.983018558Z",
     "start_time": "2023-12-12T17:46:38.863942740Z"
    }
   },
   "id": "83f802bff03db497"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:42.155444350Z",
     "start_time": "2023-12-12T17:46:42.018239621Z"
    }
   },
   "id": "c6f84382671716e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LightGCNConv architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b4a1a750141a689"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(aggr='add')\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Compute normalization\n",
    "        from_, to_ = edge_index\n",
    "        deg = degree(to_, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "        \n",
    "        # Start propagating messages (no update after aggregation)\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T17:46:43.849265775Z",
     "start_time": "2023-12-12T17:46:43.668482675Z"
    }
   },
   "id": "59ff8ee915097caf"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:54:17.640796072Z",
     "start_time": "2023-12-11T22:54:17.506988897Z"
    }
   },
   "id": "32caf98f18491722"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "645bce5d91c93e4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NGCF Conv model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d584a38dc429ff51"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "class NGCFConv(MessagePassing):\n",
    "    def __init__(self, _latent_dim, dropout, bias=True, **kwargs):  \n",
    "        super(NGCFConv, self).__init__(aggr='add', **kwargs)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lin_1 = nn.Linear(_latent_dim, _latent_dim, bias=bias)\n",
    "        self.lin_2 = nn.Linear(_latent_dim, _latent_dim, bias=bias)\n",
    "        \n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.lin_1.weight)\n",
    "        nn.init.xavier_uniform_(self.lin_2.weight)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Compute normalization\n",
    "        from_, to_ = edge_index\n",
    "        \n",
    "        deg = degree(to_, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "        \n",
    "        # Start propagating messages\n",
    "        _out = self.propagate(edge_index, x=(x, x), norm=norm)\n",
    "        \n",
    "        # Update after aggregation\n",
    "        _out += self.lin_1(x)\n",
    "        _out = F.dropout(_out, self.dropout, self.training)\n",
    "        \n",
    "        return F.leaky_relu(_out)\n",
    "\n",
    "    def message(self, x_j, x_i, norm):\n",
    "        return norm.view(-1, 1) * (self.lin_1(x_j) + self.lin_2(x_j * x_i))\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T23:21:40.146610343Z",
     "start_time": "2023-12-11T23:21:40.031603050Z"
    }
   },
   "id": "307195f91eb670d0"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:10:12.307415982Z",
     "start_time": "2023-12-11T22:10:12.246319710Z"
    }
   },
   "id": "14b969d183dcb740"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T19:42:42.689693023Z",
     "start_time": "2023-12-11T19:42:42.662118410Z"
    }
   },
   "id": "6a5a34bc7fa47029"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "RecommenderSys(\n  (embedding): Embedding(2596, 64)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (convs): ModuleList(\n    (0-1): 2 x NGCFConv()\n  )\n)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RecommenderSys(nn.Module):\n",
    "    def __init__(self, _latent_dim, _num_layers, num_users, num_items, dropout=0.5):\n",
    "        super(RecommenderSys, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_users + num_items, _latent_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # NGCF convs\n",
    "        self.convs = nn.ModuleList(NGCFConv(_latent_dim, dropout) for _ in range(_num_layers))\n",
    "        \n",
    "        self.init_parameters()\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.embedding.weight) \n",
    "        \n",
    "    def forward(self, edge_index):\n",
    "        emb_init = self.embedding.weight\n",
    "        embs = [emb_init]\n",
    "        \n",
    "        emb = emb_init\n",
    "        for conv in self.convs:\n",
    "            emb = conv(x=emb, edge_index=edge_index)\n",
    "            embs.append(emb)\n",
    "        \n",
    "        out = (torch.cat(embs, dim=-1))\n",
    "        \n",
    "        return emb_init, out\n",
    "        \n",
    "    def encode_minibatch(self, _users, positive_items, negative_items, edge_index):\n",
    "        emb0, _out = self(edge_index)  # .to(torch.int64))\n",
    "        \n",
    "        return (\n",
    "            _out[_users],\n",
    "            _out[positive_items],\n",
    "            _out[negative_items],\n",
    "            emb0[_users],\n",
    "            emb0[positive_items],\n",
    "            emb0[negative_items],\n",
    "        )\n",
    "\n",
    "sysss = RecommenderSys(64, 2, n_users, n_items) \n",
    "sysss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T23:26:56.561512893Z",
     "start_time": "2023-12-11T23:26:56.454596728Z"
    }
   },
   "id": "6eda553f0c616492"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T20:41:34.287226749Z",
     "start_time": "2023-12-11T20:41:34.174434532Z"
    }
   },
   "id": "582c739ff661dafa"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T20:41:34.391249396Z",
     "start_time": "2023-12-11T20:41:34.297088429Z"
    }
   },
   "id": "6f2c738ba8a6e26d"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# BPR loss \n",
    "def compute_bpr_loss(_users, user_emb, pos_emb_, neg_emb_, init_user_emb, init_pos_emb, init_neg_emb):\n",
    "    # Compute loss from initial embeddings, for regularization \n",
    "    reg_loss_ = (1/2) * (init_user_emb.norm().pow(2) + init_pos_emb.norm().pow(2) + init_neg_emb.norm().pow(2)) / float(len(_users))\n",
    "    \n",
    "    # Compute BPR loss from user, and positive item, and negative item embeddings\n",
    "    pos_scores = torch.mul(user_emb, pos_emb_).sum(dim=1)\n",
    "    neg_scores = torch.mul(user_emb, neg_emb_).sum(dim=1)\n",
    "    \n",
    "    bpr_loss_ = torch.mean(F.softplus(neg_scores - pos_scores))\n",
    "    \n",
    "    return bpr_loss_, reg_loss_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T23:30:49.120836578Z",
     "start_time": "2023-12-11T23:30:49.021358143Z"
    }
   },
   "id": "87889966ce374838"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:08:34.037512989Z",
     "start_time": "2023-12-11T22:08:33.994056786Z"
    }
   },
   "id": "8585c1fb82149b9e"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def get_metrics(user_embeddings, item_embeddings, n_users_, n_items_, train_data_, test_data_, K):\n",
    "    # test_user_ids = torch.LongTensor(test_data_['user_id_index'].unique())\n",
    "    # test_user_Embed_wts = user_embeddings[test_user_ids]\n",
    "    \n",
    "    # compute the score of all user-item pairs\n",
    "    relevance_score = torch.matmul(user_embeddings, torch.transpose(item_embeddings, 0, 1))\n",
    "    \n",
    "    # create dense tensor of all user-item interactions\n",
    "    # i = torch.stack((\n",
    "    # torch.LongTensor(train_df['user_id_index'].values),\n",
    "    # torch.LongTensor(train_df['item_id_index'].values)\n",
    "    # ))\n",
    "    # v = torch.ones((len(train_df)), dtype=torch.float64)\n",
    "\n",
    "    # Dense tensor for all user-item interactions in the training data\n",
    "    i = torch.stack((\n",
    "        torch.LongTensor(train_data_['user_id_index'].values),\n",
    "        torch.LongTensor(train_data_['item_id_index'].values)\n",
    "    ))\n",
    "    v = torch.ones((len(train_data_)), dtype=torch.float64)\n",
    "\n",
    "    interactions_t = torch.sparse.FloatTensor(i, v, (n_users_, n_items_)).to_dense().to(device)\n",
    "    \n",
    "    # mask out training user-item interactions from metric computation\n",
    "    relevance_score = torch.mul(relevance_score, (1 - interactions_t))\n",
    "    \n",
    "    # compute top scoring items for each user\n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    topk_relevance_indices_df = pd.DataFrame(\n",
    "        topk_relevance_indices.cpu().numpy(),\n",
    "        columns=['top_index_'+str(x+1) for x in range(K)]\n",
    "    )\n",
    "    topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n",
    "    topk_relevance_indices_df['top_relevant_item'] = topk_relevance_indices_df[['top_index_'+str(x+1) for x in range(K)]].values.tolist()\n",
    "    topk_relevance_indices_df = topk_relevance_indices_df[['user_ID', 'top_relevant_item']]\n",
    "    \n",
    "    # measure overlap between recommended (top-scoring) and held-out user-item interactions\n",
    "    test_interacted_items = test_data_.groupby('user_id_index')['item_id_index'].apply(list).reset_index()\n",
    "    \n",
    "    metrics_df = pd.merge(\n",
    "        test_interacted_items,\n",
    "        topk_relevance_indices_df,\n",
    "        how='left',\n",
    "        left_on='user_id_index',\n",
    "        right_on = ['user_ID']\n",
    "    )\n",
    "    metrics_df['intersecting_item'] = [\n",
    "        list(set(a).intersection(b)) for a, b in zip(metrics_df.item_id_index, metrics_df.top_relevant_item)\n",
    "    ]\n",
    "    \n",
    "    metrics_df['recall'] = metrics_df.apply(lambda x : len(x['intersecting_item']) / len(x['item_id_index']), axis=1) \n",
    "    metrics_df['precision'] = metrics_df.apply(lambda x : len(x['intersecting_item']) / K, axis=1)\n",
    "    \n",
    "    return metrics_df['recall'].mean(), metrics_df['precision'].mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:26:18.137629589Z",
     "start_time": "2023-12-12T00:26:17.996952301Z"
    }
   },
   "id": "32353370c0aa8751"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:08:36.697335825Z",
     "start_time": "2023-12-11T22:08:36.640600829Z"
    }
   },
   "id": "7d885f13a099d791"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/patrick/Documents/MSc/Fall23/Project/notebooks/wandb/run-20231211_193857-9mthwht6</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6' target=\"_blank\">glorious-dew-4</a></strong> to <a href='https://wandb.ai/hidden-leaf/recsys-gnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/hidden-leaf/recsys-gnn' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f4501a7c850>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"recsys-gnn\", group=\"ngcf\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:38:58.923438256Z",
     "start_time": "2023-12-12T00:38:57.898149341Z"
    }
   },
   "id": "9af0dfbaeaa25d3e"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "num_layers = 3\n",
    "batch_size = 2048\n",
    "epochs = 50\n",
    "decay = 1e-4\n",
    "learning_rate = 1e-3\n",
    "k = 20 \n",
    "\n",
    "config = {\n",
    "    \"latent_dim\": latent_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"epochs\": epochs,\n",
    "    \"decay\": decay,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"k\": k,\n",
    "}\n",
    "wandb.config.update(config)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:39:00.389386814Z",
     "start_time": "2023-12-12T00:39:00.317248184Z"
    }
   },
   "id": "3a956ba0ef2bd82c"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:39:02.086055357Z",
     "start_time": "2023-12-12T00:39:02.017791304Z"
    }
   },
   "id": "7db19da628a65f2f"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "global_counter = 0\n",
    "\n",
    "model = RecommenderSys(latent_dim, num_layers, n_users, n_items)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:39:11.660603616Z",
     "start_time": "2023-12-12T00:39:11.540808948Z"
    }
   },
   "id": "2d06b143cb99f667"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# # global_counter = 0\n",
    "# \n",
    "# def train_and_eval(model, optimizer, train_df):\n",
    "#     loss_list_epoch = []\n",
    "#     bpr_loss_list_epoch = []\n",
    "#     reg_loss_list_epoch = []\n",
    "#     \n",
    "#     recall_list = []\n",
    "#     precision_list = []\n",
    "# \n",
    "#     for epoch in tqdm(range(epochs)):\n",
    "#         n_batch = int(len(train_df) / batch_size)\n",
    "#     \n",
    "#         final_loss_list = []\n",
    "#         bpr_loss_list = []\n",
    "#         reg_loss_list = []\n",
    "#     \n",
    "#         model.train()\n",
    "#         for batch_idx in range(n_batch):\n",
    "#     \n",
    "#             optimizer.zero_grad()\n",
    "#             \n",
    "#             users, pos_items, neg_items = data_loader(train_df, batch_size, n_users, n_items)\n",
    "#             users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0 = model.encode_minibatch(users, pos_items, neg_items, train_edge_index)\n",
    "#             \n",
    "#             bpr_loss, reg_loss = compute_bpr_loss(users, users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0)\n",
    "#             reg_loss = decay * reg_loss\n",
    "#             final_loss = bpr_loss + reg_loss\n",
    "#             \n",
    "#             final_loss.backward()\n",
    "#             optimizer.step()\n",
    "#             \n",
    "#             final_loss_list.append(final_loss.item())\n",
    "#             bpr_loss_list.append(bpr_loss.item())\n",
    "#             reg_loss_list.append(reg_loss.item())\n",
    "#             \n",
    "#             wandb.log({\n",
    "#                 \"epoch\": epoch,\n",
    "#                 # \"batch_idx\": batch_idx,\n",
    "#                 \"training loss\": final_loss.item(),\n",
    "#                 \"bpr_loss\": bpr_loss.item(),\n",
    "#                 \"reg_loss\": reg_loss.item(),\n",
    "#             }, step=global_counter)\n",
    "# \n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             _, out = model(train_edge_index)\n",
    "#             final_user_Embed, final_item_Embed = torch.split(out, (n_users, n_items))\n",
    "#             test_topK_recall,  test_topK_precision = get_metrics(\n",
    "#             final_user_Embed, final_item_Embed, n_users, n_items, train_df, test_df, k\n",
    "#             )\n",
    "# \n",
    "#         loss_list_epoch.append(round(np.mean(final_loss_list),4))\n",
    "#         bpr_loss_list_epoch.append(round(np.mean(bpr_loss_list),4))\n",
    "#         reg_loss_list_epoch.append(round(np.mean(reg_loss_list),4))\n",
    "#         \n",
    "#         recall_list.append(round(test_topK_recall,4))\n",
    "#         precision_list.append(round(test_topK_precision,4))\n",
    "#         \n",
    "#         global_counter += 1\n",
    "# \n",
    "#     return (\n",
    "#         loss_list_epoch, \n",
    "#         bpr_loss_list_epoch, \n",
    "#         reg_loss_list_epoch, \n",
    "#         recall_list, \n",
    "#         precision_list\n",
    "#     )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:18:07.821620839Z",
     "start_time": "2023-12-11T22:18:07.757564598Z"
    }
   },
   "id": "fad55b223d768e62"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:06<00:00,  6.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bpr_loss</td><td>█▆▇▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▃▃▃▂▂▂▂▃▂▁▂▂▂▁▂▂▁▂▂▁▁</td></tr><tr><td>reg_loss</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_topK@20_precision</td><td>▁▁▁▁▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>test_topK@20_recall</td><td>▁▁▁▁▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇███████████</td></tr><tr><td>training loss</td><td>█▆▇▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▃▃▃▂▂▂▂▃▂▁▂▂▂▁▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bpr_loss</td><td>0.22674</td></tr><tr><td>reg_loss</td><td>4e-05</td></tr><tr><td>test_topK@20_precision</td><td>0.24644</td></tr><tr><td>test_topK@20_recall</td><td>0.30128</td></tr><tr><td>training loss</td><td>0.22678</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">glorious-dew-4</strong> at: <a href='https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn/runs/9mthwht6</a><br/> View job at <a href='https://wandb.ai/hidden-leaf/recsys-gnn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjgzNzAzMQ==/version_details/v3' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyMjgzNzAzMQ==/version_details/v3</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20231211_193857-9mthwht6/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    n_batch = int(len(train_df) / batch_size)\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx in range(n_batch):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        users, pos_items, neg_items = data_loader(train_df, batch_size, n_users, n_items)\n",
    "        \n",
    "        users_emb, pos_emb, neg_emb, userEmb0, posEmb0, negEmb0 = model.encode_minibatch(users, pos_items, neg_items, train_edge_index)\n",
    "        \n",
    "        bpr_loss, reg_loss = compute_bpr_loss(users, users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0)\n",
    "        reg_loss *= decay  #  * reg_loss\n",
    "        final_loss = bpr_loss + reg_loss\n",
    "        \n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({\n",
    "            # \"epoch\": epoch,\n",
    "            # \"batch_idx\": batch_idx,\n",
    "            \"training loss\": final_loss.item(),\n",
    "            \"bpr_loss\": bpr_loss.item(),\n",
    "            \"reg_loss\": reg_loss.item(),\n",
    "        }, step=global_counter)\n",
    "\n",
    "        global_counter += 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, out = model(train_edge_index)\n",
    "        \n",
    "        final_user_embed, final_item_embed = torch.split(out, (n_users, n_items))\n",
    "        \n",
    "        test_topK_recall, test_topK_precision = get_metrics(\n",
    "            final_user_embed,\n",
    "            final_item_embed,\n",
    "            n_users,\n",
    "            n_items,\n",
    "            train_df,\n",
    "            test_df,\n",
    "            k\n",
    "        )\n",
    "        \n",
    "        wandb.log({\n",
    "            # \"epoch\": epoch,\n",
    "            f\"test_topK@{k}_recall\": test_topK_recall,\n",
    "            f\"test_topK@{k}_precision\": test_topK_precision\n",
    "        },\n",
    "        step=global_counter)\n",
    "\n",
    "wandb.finish()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:44:32.230378167Z",
     "start_time": "2023-12-12T00:39:16.523316225Z"
    }
   },
   "id": "6a1b00f612b3b6bc"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:18:05.997169433Z",
     "start_time": "2023-12-12T00:18:05.868830987Z"
    }
   },
   "id": "b2a1dee4c51ba9d3"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T00:18:06.904018880Z",
     "start_time": "2023-12-12T00:18:06.794345778Z"
    }
   },
   "id": "63118fae25d8670"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross validation\n",
    "\n",
    "with optuna"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b0d9b4f894a91d"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    dim = trial.suggest_int(\"latent_dim\", 16, 128)\n",
    "    n_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    \n",
    "    model_ = RecommenderSys(dim, n_layers, n_users, n_items).to(device)\n",
    "    \n",
    "    return model_\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T01:51:14.867746823Z",
     "start_time": "2023-12-12T01:51:14.749904104Z"
    }
   },
   "id": "dbfdc48a768af26b"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T01:51:18.508043864Z",
     "start_time": "2023-12-12T01:51:18.447389874Z"
    }
   },
   "id": "31f91e182b3e6fb3"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    wandb.init(project=\"recsys-gnn\", group=\"ngcf-crossval\")\n",
    "    \n",
    "    model_ = define_model(trial)\n",
    "    \n",
    "    lr_ = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    wt_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    optimizer = optim.AdamW(model_.parameters(), lr=lr_)\n",
    "    \n",
    "    wandb.config.update({\n",
    "        \"learning_rate\": lr_,\n",
    "        \"weight_decay\": wt_decay\n",
    "    })\n",
    "    wandb.watch(model, log=\"all\")\n",
    "    \n",
    "    global_counter_ = 0\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        n_batch_ = int(len(train_df) / batch_size)\n",
    "    \n",
    "        model.train()\n",
    "        for batch_idx_ in range(n_batch_):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            users, pos_items, neg_items = data_loader(train_df, batch_size, n_users, n_items)\n",
    "            \n",
    "            users_emb, pos_emb, neg_emb, userEmb0, posEmb0, negEmb0 = model_.encode_minibatch(users, pos_items, neg_items, train_edge_index)\n",
    "            \n",
    "            bpr_loss, reg_loss = compute_bpr_loss(users, users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0)\n",
    "            reg_loss *= wt_decay  #  * reg_loss\n",
    "            final_loss = bpr_loss + reg_loss\n",
    "            \n",
    "            final_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            wandb.log({\n",
    "                \"training loss\": final_loss.item(),\n",
    "                \"bpr_loss\": bpr_loss.item(),\n",
    "                \"reg_loss\": reg_loss.item(),\n",
    "            }, step=global_counter_)\n",
    "    \n",
    "            global_counter_ += 1\n",
    "    \n",
    "        model_.eval()\n",
    "        with torch.no_grad():\n",
    "            _, out = model_(train_edge_index)\n",
    "            \n",
    "            final_user_embed, final_item_embed = torch.split(out, (n_users, n_items))\n",
    "            \n",
    "            test_topK_recall, test_topK_precision = get_metrics(\n",
    "                final_user_embed,\n",
    "                final_item_embed,\n",
    "                n_users,\n",
    "                n_items,\n",
    "                train_df,\n",
    "                test_df,\n",
    "                k\n",
    "            )\n",
    "            \n",
    "            wandb.log({\n",
    "                # \"epoch\": epoch,\n",
    "                f\"test_topK@{k}_recall\": test_topK_recall,\n",
    "                f\"test_topK@{k}_precision\": test_topK_precision\n",
    "            },\n",
    "            step=global_counter)\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "    trial.set_user_attr('best_model', model_)\n",
    "    \n",
    "    return test_topK_recall\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:55:57.859215281Z",
     "start_time": "2023-12-12T02:55:57.756940031Z"
    }
   },
   "id": "a722200f1e5498db"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def call_back(study_, trial):\n",
    "    if study_.best_trial.number == trial.number:\n",
    "        study_.set_user_attr('best_model', trial.user_attrs['best_model'])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:55:59.600507065Z",
     "start_time": "2023-12-12T02:55:59.527050562Z"
    }
   },
   "id": "ca0265f2de55a2d8"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-11 21:56:01,164] A new study created in memory with name: no-name-fd9159e6-0cb9-4e46-bea5-90423a6cdcf8\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction='maximize')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:56:01.242019984Z",
     "start_time": "2023-12-12T02:56:01.168428064Z"
    }
   },
   "id": "fb0ba56e67062106"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/patrick/Documents/MSc/Fall23/Project/notebooks/wandb/run-20231211_215606-eo15xcts</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/hidden-leaf/recsys-gnn/runs/eo15xcts' target=\"_blank\">fanciful-feather-5</a></strong> to <a href='https://wandb.ai/hidden-leaf/recsys-gnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/hidden-leaf/recsys-gnn' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/hidden-leaf/recsys-gnn/runs/eo15xcts' target=\"_blank\">https://wandb.ai/hidden-leaf/recsys-gnn/runs/eo15xcts</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:07<06:17,  7.71s/it]\n",
      "[W 2023-12-11 21:56:14,991] Trial 0 failed with parameters: {'latent_dim': 42, 'num_layers': 2, 'learning_rate': 0.0003585815106995502, 'weight_decay': 7.54296403702685e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/patrick/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2599943/3326939693.py\", line 38, in objective\n",
      "    \"training loss\": final_loss.item(),\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-11 21:56:14,993] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[146], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcall_back\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    360\u001B[0m \n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    250\u001B[0m ):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/Documents/MSc/Fall23/Project/proj-env/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn[143], line 38\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     34\u001B[0m     final_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     35\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     37\u001B[0m     wandb\u001B[38;5;241m.\u001B[39mlog({\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mfinal_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbpr_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: bpr_loss\u001B[38;5;241m.\u001B[39mitem(),\n\u001B[1;32m     40\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreg_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: reg_loss\u001B[38;5;241m.\u001B[39mitem(),\n\u001B[1;32m     41\u001B[0m     }, step\u001B[38;5;241m=\u001B[39mglobal_counter_)\n\u001B[1;32m     43\u001B[0m     global_counter_ \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     45\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=50, callbacks=[call_back])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:56:15.511299077Z",
     "start_time": "2023-12-12T02:56:06.073995942Z"
    }
   },
   "id": "925602292fe9830c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3f027441d3f20f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "proj-env",
   "language": "python",
   "display_name": "proj-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
